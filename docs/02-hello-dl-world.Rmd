---
title: "Hello [Deep Learning] World"
author: "Brad Boehmke"
date: "2020-01-27"
output:
  xaringan::moon_reader:
    css: ["custom.css"]
    self_contained: false
    lib_dir: libs
    chakra: libs/remark-latest.min.js
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: clear, center, middle

background-image: url(images/MnistExamples.png)
background-size: cover

.font1000.bold[MNIST]

```{r setup, include=FALSE, cache=FALSE}
# set working directory to docs folder
setwd(here::here("docs"))

# Set global R options
options(htmltools.dir.version = FALSE, servr.daemon = TRUE)

# Set global knitr chunk options
knitr::opts_chunk$set(
  fig.align = "center", 
  cache = TRUE,
  error = FALSE,
  message = FALSE, 
  warning = FALSE, 
  collapse = TRUE 
)

# Use a clean black and white ggplot2 theme
library(ggplot2)
thm <- theme_bw()
theme_set(thm)
```

---
# Origination

.scrollable90[
.pull-left[

* National Institute of Standards and Technology (NIST) database

* MNIST (Modified NIST)

* 60,000 training images and 10,000 testing images

* normalized to fit into a 28x28 pixel bounding box

]

.pull-right[

```{r nist-sample-form, echo=FALSE}
knitr::include_graphics("images/nist-sample-form.png")
```

]
]

---
# Important benchmark

.scrollable90[
.pull-left[

* Used as an important benchmark for image processing from 1990s - 2012

* 1998: 12% error rate

* 2012: 0.23% error rate

* Website: http://yann.lecun.com/exdb/mnist/

]

.pull-right[

```{r mnist-benchmarks, echo=FALSE}
knitr::include_graphics("images/MNIST-benchmarks.png")
```

]
]

---
class: clear, center, middle

.font1000.bold[`%<-%`]

.font300[object unpacking]

---
# zeallot `r anicon::faa("box-open", animate = FALSE)`

Object unpacking mimicks tuple unpacking in Python

--

A simple vector

```{r}
my_name <- c('Brad', 'Boehmke')
```

--

.pull-left[

Traditional assignment unpacking

```{r}
first <- my_name[1]
last <- my_name[2]
```

]

.pull-right[

Object unpacking

```{r}
c(first, last) %<-% my_name
```

]

--

Both result in:

```{r}
first
last
```


---
# zeallot `r anicon::faa("box-open", animate = FALSE)`

Object unpacking mimicks tuple unpacking in Python

A data frame

```{r}
head(mtcars)
```


.pull-left[

Traditional assignment unpacking

```{r}
# data frames
mpg <- mtcars$mpg
cyl <- mtcars$cyl
disp <- mtcars $disp
hp <- mtcars$hp
```

]

.pull-right[

Object unpacking

```{r}
# data frames
c(mpg, cyl, disp, hp) %<-% mtcars[, 1:4]
```

]

Both result in:

```{r}
mpg
cyl
disp
hp
```


---
# zeallot `r anicon::faa("box-open", animate = FALSE)`

```{r}
mnist <- dataset_mnist()
str(mnist)
```

.pull-left[

Traditional assignment unpacking

```{r}
mnist <- dataset_mnist()

train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
```

]

.pull-right[

Object unpacking

```{r}
c(c(train_images, train_labels), c(test_images, test_labels)) %<-% mnist
```

]

---
class: clear, center, middle

.font1000.bold[Tensors]
---
# The .red[tensor] in TensorFlow

.pull-left[

```{r, echo=FALSE}
knitr::include_graphics("images/whats_a_tensor.png")
```

]

--

.pull-right[
<br><br><br>
.center.bold[
_Don't worry, you actually use tensors everyday (at least everyday you use R!)_
]
]

---
# The .red[tensor] in TensorFlow

.pull-left[

<br><br><br><br>

```{r, echo=FALSE, fig.width=1}
knitr::include_graphics("images/1D_tensor.png")
```

]

.pull-right[
<br><br><br>
.center.bold.opacity20[
_Don't worry, you actually use tensors everyday (at least everyday you use R!)_
]
.center.bold.blue[Vectors are 1D tensors]

]

---
# The .red[tensor] in TensorFlow

.pull-left[

<br><br>

```{r, echo=FALSE}
knitr::include_graphics("images/2D_tensor.png")
```

]

.pull-right[
<br><br><br>
.center.bold.opacity20[
_Don't worry, you actually use tensors everyday (at least everyday you use R!)_

Vectors are 1D tensors
]
.center.bold.blue[Matrices are 2D tensors]

]

---
# MNIST tensor

* Since our MNIST data are gray scale it can be represented as a 2D tensor
* We just needed to reshape it so:
   - each column `r anicon::faa("hand-point-right", color = "red", animate = "horizontal")` feature
   - each row `r anicon::faa("hand-point-right", color = "red", animate = "horizontal")` observation
   
.pull-left[

.center[`array_reshape` reshapes 3D array to...]

```{r, echo=FALSE}
knitr::include_graphics("images/untidy_matrix.png")
```


]

.pull-right[

.center[2D tensor]

```{r, echo=FALSE}
knitr::include_graphics("images/tidy_matrix.png")
```

]

---
# .red[Tensor] benefits

<br>

* .red.bold[Generalization]: Tensors generalize vectors and matrices to an arbitary
number of dimensions,

* .red.bold[Flexibility]: can hold a wide range of data dimensions,

* .red.bold[Speed]: provide fast, parallel processing computations.

<br><br><br><br><br><br>

--

.center.bold[_They just get a bit complicated when you start working with higher dimensions_]

---
# .red.bold[3D] Tensor

.pull-left[

* Represented as arrays

* Sequence data
   - time series
   - text
   - dim = (observations, seq steps, features)

* Examples
   - 250 days of high, low, and current stock price for 390 minutes of trading
   in a day; dim = c(250, 390, 3)
   - 1M tweets that can be 140 characters long and include 128 unique characters; dim = c(1M, 140, 128)

]

.pull-right[

```{r, echo=FALSE}
knitr::include_graphics('images/3D_tensor.png')
```

]

---
# .red.bold[4D] Tensor

.pull-left[

* Represented as arrays

* Image data
   - RGB channels
   - dim = (observations, height, width, color_depth)


]

.pull-right[

```{r, echo=FALSE}
knitr::include_graphics('images/4D_tensor.png')
```

]

---
# .red.bold[4D] Tensor

.pull-left[

* Represented as arrays

* Image data
   - RGB channels
   - dim = (observations, height, width, .red[color_depth])

* Technically, we could treat our original MNIST data as a 4D tensor where
.red[color_depth = 1]

* We'll see this play out when we start working with CNNs

]

.pull-right[

<br><br>

```{r, echo=FALSE}
knitr::include_graphics("images/untidy_matrix.png")
```

]

---
# .red.bold[5D] Tensor

.pull-left[

* Represented as arrays

* Video data
   - samples: 4 (each video is 1 minute long)
   - frames: 240 (4 frames/second)
   - width: 256 (pixels)
   - height: 144 (pixels)
   - channels: 3 (red, green, blue)
   
* Tensor shape (4, 240, 256, 144, 3)   

]

.pull-right[

```{r, echo=FALSE}
knitr::include_graphics("images/5D_tensor.jpg")
```

]

---
# Now you know what tensors are

.pull-left[

<br>

* Tensors aren't that bad, humans are just really bad at visualizing multiple dimensions! 

* Feeling comfortable will come with practice

]

.pull-right[

<br>

```{r, echo=FALSE}
knitr::include_graphics("images/tensors_everywhere.jpeg")
```

]

---
class: clear, center, middle

.font500.bold[Network architecture]

---
# Sequential vs functional

.pull-left[

```{r, echo=FALSE}
knitr::include_graphics("images/sequential_model.png")
```

* Creating a single linear stack of layers
* Most common type of neural networks
* Examples:
   - Predicting sales price based on tabular data of home characteristics,
   - Predicting animal based on image,
   - Predicting author based on text,
   - Predicting hurricane path based on numeric meteorologic data.

]

--

.pull-right[

```{r, echo=FALSE}
knitr::include_graphics("images/functional_model.png")
```

* More advanced modeling
* Allows flexible, customizable model structures
* Examples:
   - Predicting presence of cancer based on images <u>.bold[_and_]</u> patient 
   transcripts,
   - Forecasting time <u>.bold[_and_]</u> volume of sale based on tabular 
   transaction data <u>.bold[_and_]</u> customer text.

]

---
# Densely connected layers

.pull-left[
* `layer_dense()` is creating what's called a .bold[_fully connected feed forward neural network_]

* Fundamental building block of nearly all deep learning models
]

.pull-right[
```{r, echo=FALSE}
knitr::include_graphics("images/basic_mlp.png")
```
]

---
# Densely connected layers

.pull-left[
* `layer_dense()` is creating what's called a .bold[_fully connected feed forward neural network_]

* Fundamental building block of nearly all deep learning models

* So why do we call `layer_dense()` twice?  And what about the arguments inside?

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) %>% #<<
  layer_dense(units = 10, activation = 'softmax') #<<
```

]

.pull-right[
```{r, echo=FALSE}
knitr::include_graphics("images/basic_mlp.png")
```
]

---
# Densely connected layers

.pull-left[

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense() %>% # hidden layer #<< 
  layer_dense() # output layer #<<
```

* .font100[Each `layer_dense()` represents a the number of hidden layers along 
with the final output layer]

]

.pull-right[
```{r, echo=FALSE}
knitr::include_graphics("images/basic_mlp.png")
```

]

<br>

.center[.content-box-grey[We refer to a neural network with one or more hidden layer as a .blue[_multi-layer perceptron_]]]

---
# Densely connected layers

.pull-left[

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense() %>% # hidden layer 1 #<< 
  layer_dense() %>% # hidden layer 2 #<< 
  layer_dense() %>% # hidden layer 3 #<< 
  layer_dense() # output layer #<<
```

* We can add multiple hidden layers by adding more `layer_dense()` functions

* Technically, .blue[_deep learning_] refers to any neural network that has 
2 or more hidden layers

* The last `layer_dense()` will always represent the output layer

]

.pull-right[
```{r, echo=FALSE}
knitr::include_graphics("images/basic_feedforward.png")
```
]

---
# Hidden layer

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) # hidden layer #<<
```

--

.pull-left[

* `units = 512`: number of nodes in the given layer

* `input_shape = c(28 * 28)`
   - tells the first hidden layer how many input features there are
   - only required for the first `layer_dense`

]

.pull-right[
```{r, echo=FALSE}
knitr::include_graphics("images/hidden_layer.png")
```
]

---
# Hidden layer

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) # hidden layer #<<
```

.pull-left[

* `units = 512`: number of nodes in the given layer

* `input_shape = c(28 * 28)`
   - tells the first hidden layer how many input features there are
   - only required for the first `layer_dense`

* `activation`: `r anicon::cia("https://emojis.slackmojis.com/emojis/images/1499373537/2585/homer_thinking.png?1499373537", animate=FALSE)`
]

.pull-right[
```{r, echo=FALSE}
knitr::include_graphics("images/perceptron_zoom.png")
```
]

---
# Individual perceptron

.font100.pull-left[

* There is a two-step computation process when data go forward through a node

]

.pull-right[
```{r, echo=FALSE}
knitr::include_graphics("images/perceptron1.png")
```
]

---
# Individual perceptron

.font100.pull-left[

* There is a two-step computation process when data go forward through a node

* Step 1: _linear transformation_
   - $z = w_0b_0 + w_1x_1 + w_2x_2 + \cdots + w_nx_n$
   - note the extra bias term which is typically always set to 1

]

.pull-right[
```{r, echo=FALSE}
knitr::include_graphics("images/perceptron2.png")
```
]

---
# Individual perceptron

.pull-left[

* There is a two-step computation process when data go forward through a node

* .opacity20[Step 1: linear transformation]

* Step 2: _activation function_
   - in hidden layers, the most common activation function is the $\text{ReLU} = max(0, x)$
   - You will be introduced to other activation functions but ReLU should nearly
   always be your default for hidden layers
   
```{r, echo=FALSE, fig.height=2, fig.width=4}
x <- seq(-1, 1, by = 0.1)
y <- ifelse(x < 0, 0, x)
df <- data.frame(x, y)
ggplot(df, aes(x, y)) + 
   geom_line() +
   xlab("z") +
   ylab("f(z)")
```
   

]

.pull-right[
```{r, echo=FALSE}
knitr::include_graphics("images/perceptron3.png")
```
]

---
# Output layer

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) %>%
  layer_dense(units = 10, activation = 'softmax') #<<
```

---
# Output layer

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) %>%
  layer_dense(units = 10, activation = 'softmax')
```

.font100.pull-left[
Two primary arguments of concern for the final output layer:

1. number of units
   - regression: `units = 1`:


]

.pull-right[

```{r, echo=FALSE, out.height="80%", out.width="80%"}
knitr::include_graphics("images/output_layer_continuous.png")
```

]

---
# Output layer

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) %>%
  layer_dense(units = 10, activation = 'softmax')
```

.font100.pull-left[
Two primary arguments of concern for the final output layer:

1. number of units
   - regression: `units = 1`:
   - binary classification: `units = 2`

]

.pull-right[

```{r, echo=FALSE, out.height="80%", out.width="80%"}
knitr::include_graphics("images/output_layer_binary.png")
```

]


---
# Output layer

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) %>%
  layer_dense(units = 10, activation = 'softmax') #<<
```

.font100.pull-left[
Two primary arguments of concern for the final output layer:

1. number of units
   - regression: `units = 1`:
   - binary classification: `units = 2`
   - multi-class classification: `units = n`

]

.pull-right[

```{r, echo=FALSE,  out.height="75%", out.width="75%"}
knitr::include_graphics("images/output_layer_multi.png")
```

]

---
# Output layer

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) %>%
  layer_dense(units = 10, activation = 'softmax')
```

.font100.pull-left[
Two primary arguments of concern for the final output layer:

1. .opacity20[number of units]
2. activation function
   - regression: `activation = NULL` (identity function)

]

.pull-right.center[

```{r, echo=FALSE}
knitr::include_graphics("images/activation_identity.png")
```

$y = w_0b_0 + w_1h^1_1 + w_2h^1_2 + \cdots + w_nh^1_n$

]

---
# Output layer

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) %>%
  layer_dense(units = 10, activation = 'softmax') 
```

.font100.pull-left[
Two primary arguments of concern for the final output layer:

1. .opacity20[number of units]
2. activation function
   - regression: `activation = NULL` (identity function)
   - binary classification: `activation = 'sigmoid'`

]

.pull-right.center[

```{r, echo=FALSE, fig.height=3.5}
x <- seq(-5, 5, by = 0.01)
y <- 1 / (1 + exp(-x))
df <- data.frame(x, y)
ggplot(df, aes(x, y)) + 
   geom_line() +
   xlab("y") +
   ylab("f(y)") +
   ggtitle("Sigmoid activation function")
```

$f(y) = \frac{1}{1 + e^{-y}}$

]

---
# Output layer

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) %>%
  layer_dense(units = 10, activation = 'softmax') #<<
```

.font100.pull-left[
Two primary arguments of concern for the final output layer:

1. .opacity20[number of units]
2. activation function
   - regression: `activation = NULL` (identity function)
   - binary classification: `activation = 'sigmoid'`
   - multi-class classification: `activation = 'softmax'`

]

.pull-right.center[

```{r, echo=FALSE}
knitr::include_graphics("images/softmax.png")
```

$f(y) = \frac{e^{y_i}}{\sum_je^{y_j}}$

]

---
# Output layer

```{r, eval=FALSE}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(28 * 28)) %>%
  layer_dense(units = 10, activation = 'softmax') #<<
```

.font100.pull-left[
Two primary arguments of concern for the final output layer:

1. .opacity20[number of units]
2. activation function
   - regression: `activation = NULL` (identity function)
   - binary classification: `activation = 'sigmoid'`
   - multi-class classification: `activation = 'softmax'`

]

.pull-right.center[

```{r, echo=FALSE}
knitr::include_graphics("images/softmax.png")
```

]

.center[.content-box-grey.font90.blue[_This is why we used `to_categorical()`, so that we can get the probabilities for each output class._]]

---
# Network architecture summary

.pull-left-30.font80[

1. A sequential, dense, fully connected neural network

2. 784 inputs

3. 1 hidden layer  
   a. 512 nodes  
   b. ReLU activation function
<br><br>   
  
4. multi-class output layer  
   a. 10 nodes (1 for each output)  
   b. Softmax activation function
]

.pull-right-70[

```{r, echo=FALSE}
knitr::include_graphics("images/network_architecture_summary.png")
```

]

---
# Network architecture summary

.pull-left.font80[

1. A sequential, dense, fully connected neural network

2. 784 inputs

3. 1 hidden layer  
   a. 512 nodes  
   b. ReLU activation function  
   $params = (784 \times 512) + 512 = 401920$
   
4. multi-class output layer  
   a. 10 nodes  
   b. Softmax activation function  
   $params = (512 \times 10) + 10 = 5130$
]

.pull-right[

```{r, eval=FALSE}
summary(network)
## Model: "sequential"
## ______________________________________________________________________________________
## Layer (type)                          Output Shape                       Param #      
## ======================================================================================
## dense (Dense)                         (None, 512)                        401920       
## ______________________________________________________________________________________
## dense_1 (Dense)                       (None, 10)                         5130         
## ======================================================================================
## Total params: 407,050
## Trainable params: 407,050
## Non-trainable params: 0
## ______________________________________________________________________________________
```

]

---
class: clear, center, middle

.font500.bold[Network compilation]

---
# Forward pass

.pull-left[

]

.pull-right[

```{r, echo=FALSE}
knitr::include_graphics("images/forward_pass.png")
```

]

---
# Forward pass

.pull-left.font120[
<br><br>
* Weights are _initialized_ as very small random values

]

.pull-right[

```{r, echo=FALSE}
knitr::include_graphics("images/forward_pass.png")
```

]

---
# Forward pass

.pull-left.font100[
<br><br><br>
* Weights are _initialized_ as very small random values

* Results in predicted values that are significantly different then the actual
targets

]

.pull-right[

```{r, echo=FALSE}
knitr::include_graphics("images/forward_pass2.png")
```

]

---
# Forward pass

.pull-left.code70[
<br><br><br>
* Weights are _initialized_ as very small random values

* Results in predicted values that are significantly different then the actual
targets

* We measure this difference with a _loss function_

```{r, eval=FALSE}
network %>% compile(
  loss = "categorical_crossentropy", #<<
  optimizer = "rmsprop",
  metrics = c("accuracy")
)
```


]

.pull-right[

```{r, echo=FALSE}
knitr::include_graphics("images/forward_pass3.png")
```

]

---
# Loss function

_Loss function (objective function)_ : the quantity that will be minimized during training.

.pull-left[

* Many options

* Should use the one that aligns best to the problem at hand; however,...

]

.pull-right[

* mean squared error (MSE)
* mean absolute error (MAE)
* mean absolute percentage error (MAPE)
* mean squared logarithmic error (MSLE)
* squared hinge
* log cosine hinge
* binary cross entropy
* categorical hinge
* categorical cross entropy
* sparse categorical cross entropy
* Kullback-Leibler divergence
* Poisson
* cosine proximity
* can even build your own custom loss functions!

]

---
# Loss function

_Loss function (objective function)_ : the quantity that will be minimized during training.

.pull-left[

* Many options

* Should use the one that aligns best to the problem at hand; however,...

* general recommendations for common problems include:
   - Regression: MSE
   - Binary classification: binary crossentropy
   - Multi-class classification: categorical crossentropy

]

.pull-right[

* .blue[mean squared error (MSE)]
* mean absolute error (MAE)
* mean absolute percentage error (MAPE)
* mean squared logarithmic error (MSLE)
* squared hinge
* log cosine hinge
* .blue[binary cross entropy]
* categorical hinge
* .blue[categorical cross entropy]
* sparse categorical cross entropy
* Kullback-Leibler divergence
* Poisson
* cosine proximity
* can even build your own custom loss functions!

]

---
# Loss function

_Loss function (objective function)_ : the quantity that will be minimized during training.

.pull-left[

* Many options

* Should use the one that aligns best to the problem at hand; however,...

* general recommendations for common problems include:
   - Regression: MSE
   - Binary classification: binary crossentropy
   - Multi-class classification: categorical crossentropy

   
.center[.content-box-grey.font80[_All three heavily penalize bad predictions!_]]

]

.pull-right[

* .blue[mean squared error (MSE)]
* mean absolute error (MAE)
* mean absolute percentage error (MAPE)
* mean squared logarithmic error (MSLE)
* squared hinge
* log cosine hinge
* .blue[binary cross entropy]
* categorical hinge
* .blue[categorical cross entropy]
* sparse categorical cross entropy
* Kullback-Leibler divergence
* Poisson
* cosine proximity
* can even build your own custom loss functions!

]

---
# Loss function

.pull-left[

<br><br><br><br><br>
.center.blue.bold[_Our goal is to find weights that minimize the loss score_]

]

.pull-right[

```{r, echo=FALSE}
knitr::include_graphics("images/forward_pass4.png")
```

]

---
# Backward pass


---
# Backpropagation


---
# Derivatives


---
# Gradient descent


---
# Optimizers


---
# Tacking additional metrics


---
# Network compilation summary


---
class: clear, center, middle

.font500.bold[Training loop]

